// Also called "operation" here and there, describes what a worker should do.
// The AST of RaQL language:
[ // Aggregation of several tuples into one based on some key. Superficially
  // looks like a select but much more involved. Most clauses being optional,
  // this is really the Swiss-army knife for all data manipulation in Ramen:
  Aggregate {
    // Composition of the output record, from the SELECT clause.
    fields: $raql_select_field[[]];
    // also "*" minus listed fields:
    and_all_others: $field_name[[]]?; // TODO: rename into and_all_but?
    // Optional buffering of N tuples for sorting according to some
    // expression:
    sort: ( // TODO: make this a record
      u32; // size
      $raql_expr?; // until
      $raql_expr[[]] // by
    )?;
    // Simple way to filter out incoming tuples:
    where: $raql_expr;
    // How to compute the time range for that event:
    event_time: $event_time?;
    // Will send these notification to the alerter:
    notifications: $raql_expr[[]];
    // Grouping key:
    key: $raql_expr[[]];
    // Output the group after/before this condition holds
    commit_cond: $raql_expr;
    // Commit first and aggregate later
    commit_before: bool;
    // What happen when the group value is submitted:
    flush_how: $raql_flush_method;
    // List of funcs (or sub-queries) that are our parents:
    // Possible FROM sources: other function (optionally from another program),
    // sub-query or internal instrumentation:
    from: (data_source as
      [ NamedOperation (  // TODO: make this a record
          // site
          [ AllSites
          | TheseSites string // A glob!
          | ThisSite ];
          // rel_program
          string?;
          // function
          $function_name
        )
      | SubQuery this])[[]];
    // Pause in between two productions (useful for operations with no
    // parents:
    every: $raql_expr?;
    // Fields with expected small dimensionality, suitable for breaking down
    // the time series:
    factors: $field_name[[]];
  }
| ReadExternal {
    // External data sources:
    // When not SELECTing from other ramen workers or LISTENing to known protocols
    // a worker can READ data from an external source. In that case, not only the
    // external source must be described (see external_source) but also the
    // format describing how the data is encoded must be specified (see
    // external_format).
    // In theory, both are independent, but in practice of course the container
    // specification leaks into the format specification.
    source: external_source as
      [ File {
          fname: $raql_expr;
          // Command to preprocess the file before reading:
          preprocessor: $raql_expr?;
          // Whether to unlink the file after opening it:
          unlink: $raql_expr;
        }
      | Kafka {
          // The consumer is configured with the standard configuration
          // parameters, of which "metadata.broker.list" is mandatory.
          // See https://kafka.apache.org/documentation.html#consumerconfigs
          // In particular, pay attention to "bootstrap.servers" (can be used to get
          // to the actual leader for the partition, as usual with Kafka),
          // "group.id" (the consumer group name), "client.id" to help reading
          // Kafka's logs.
          //
          // Regarding consumer groups:
          // The easiest is to use only one consumer and one consumer group. In
          // that case, that worker will receive all messages from all partitions.
          // But we may want instead to partition Kafka's topic with the key we
          // intend to group by (or just part of that key), and start several
          // workers. Now if all those workers have the same consumer group, they
          // will be send all messages from distinct partitions, thus parallelizing
          // the work.
          // If two different functions both wants to read from the same topic,
          // each of these workers willing to receive all the messages
          // notwithstanding the other workers also reading this very topic, the
          // different consumer group names have to be used.
          // A good value is the FQ name of the function.
          //
          // Regarding restarts:
          // By default, each worker saves its own kafka partitions offset in its
          // state file. The downside of course is that when that statefile is
          // obsoleted by a worker code change then the worker will have to restart
          // from fresh.
          // The other alternative is to store this offset in another file, thus
          // keeping it across code change. In that case the user specify the file
          // name in which the offset will be written in user friendly way, so she
          // can manage it herself (by deleting the file or manually altering that
          // offset).
          // Finally, it is also possible to use Kafka group coordinator to manage
          // those offset for us.
          options: (string; $raql_expr)[[]];
          topic: $raql_expr;
          // An optional vector or list ; None means all:
          partitions: $raql_expr?;
          restart_from:
            [ Beginning
            // Expecting a positive int here for negative offset from the end,
            // as in rdkafka lib:
            | OffsetFromEnd $raql_expr
            | SaveInState
            | UseKafkaGroupCoordinator {
                after_max_secs: $raql_expr;
                after_max_events: $raql_expr
              } ];
        } ];
    format: external_format as
      [ CSV {
          separator: char;
          null: string;
          // If not null, expect some fields quoted with that char.
          // Otherwise quotes are just part of the value:
          may_quote: char? default null;
          escape_seq: string default "";
          vectors_of_chars_as_string: bool default false;
          // Clickhouse uses a weird syntax for compound values:
          clickhouse_syntax: bool default false;
        }
      // ClickHouse RowBinary format taken from NamesAndTypes.cpp for version 1
      | RowBinary ];
    fields: $field_type[[]];
    event_time: $event_time?;
    factors: $field_name[[]];
  }
| ListenFor {
    net_addr: string; // TODO: Should be a string or IP valued $raql_expr
    port: u16;    // TODO: also a $raql_expr
    ip_proto: $raql_ip_protocol;
    proto: $raql_net_protocol;
    factors: $field_name[[]];
  } ]
